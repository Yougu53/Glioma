{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> \n",
    "    Enhancing Glioma Grading: Integrating Genomic and Clinical Features with Deep learning\n",
    "</center></h1>\n",
    "\n",
    "<h2>Course: CptS 534</h2>\n",
    "\n",
    "##### Jingjing Nie: 11742013, School of Electrical Engineering and Computer Science\n",
    "##### Wooyoung Kim: 11808206, Department of Mathematics and Statistics\n",
    "##### Xinyue Wu: 11809269, Department of Sociology"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Download dataset from UCI Machine learning Respository\n",
    "###### (See detail in https://archive.ics.uci.edu/dataset/759/glioma+grading+clinical+and+mutation+features+dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 759, 'name': 'Glioma Grading Clinical and Mutation Features', 'repository_url': 'https://archive.ics.uci.edu/dataset/759/glioma+grading+clinical+and+mutation+features+dataset', 'data_url': 'https://archive.ics.uci.edu/static/public/759/data.csv', 'abstract': 'Gliomas are the most common primary tumors of the brain. They can be graded as LGG (Lower-Grade Glioma) or GBM (Glioblastoma Multiforme) depending on the histological/imaging criteria. Clinical and molecular/mutation factors are also very crucial for the grading process. Molecular tests are expensive to help accurately diagnose glioma patients.    In this dataset, the most frequently mutated 20 genes and 3 clinical features are considered from TCGA-LGG and TCGA-GBM brain glioma projects.  The prediction task is to determine whether a patient is LGG or GBM with a given clinical and molecular/mutation features. The main objective is to find the optimal subset of mutation genes and clinical features for the glioma grading process to improve performance and reduce costs.  ', 'area': 'Health and Medicine', 'tasks': ['Classification', 'Other'], 'characteristics': ['Tabular', 'Multivariate'], 'num_instances': 839, 'num_features': 23, 'feature_types': ['Real', 'Categorical', 'Integer'], 'demographics': ['Gender', 'Age', 'Race'], 'target_col': ['Grade'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2022, 'last_updated': 'Fri Nov 03 2023', 'dataset_doi': '10.24432/C5R62J', 'creators': ['Erdal Tasci', 'Kevin Camphausen', 'Andra Valentina Krauze', 'Ying Zhuge'], 'intro_paper': {'title': 'Hierarchical Voting-Based Feature Selection and Ensemble Learning Model Scheme for Glioma Grading with Clinical and Molecular Characteristics', 'authors': 'E. Tasci, Y. Zhuge, Harpreet Kaur, K. Camphausen, A. Krauze', 'published_in': 'International Journal of Molecular Sciences', 'year': 2022, 'url': 'https://www.semanticscholar.org/paper/992bf4c0b92ef251644ac2854dd1baacd7e42dc5', 'doi': None}, 'additional_info': {'summary': None, 'purpose': 'Gliomas are the most common primary tumors of the brain. They can be graded as LGG (Lower-Grade Glioma) or GBM (Glioblastoma Multiforme) depending on the histological/imaging criteria. Clinical and molecular/mutation factors are also very crucial for the grading process. Molecular tests are expensive to help accurately diagnose glioma patients.  \\n\\nIn this dataset, the most frequently mutated 20 genes and 3 clinical features are considered from TCGA-LGG and TCGA-GBM brain glioma projects.\\n\\nThe prediction task is to determine whether a patient is LGG or GBM with a given clinical and molecular/mutation features. The main objective is to find the optimal subset of mutation genes and clinical features for the glioma grading process to improve performance and reduce costs.', 'funded_by': 'The Cancer Genome Atlas (TCGA) Project – NCI', 'instances_represent': 'In this dataset, the instances represent the records of patients who have brain glioma. The dataset was  constructed based on TCGA-LGG and TCGA-GBM brain glioma projects.\\n\\nEach record is characterized by 20 molecular features (each of which can be mutated or not_mutated (wildtype) depending on the TCGA Case_ID) and 3 clinical features (concerning the demographics of the patient).', 'recommended_data_splits': 'No. We suggest 10-fold cross-validation for feature selection, classification etc.', 'sensitive_data': 'There is information about race, age, and gender of the patient.', 'preprocessing_description': 'Yes. \\n\\nThe original and preprocessed files differ in the following ways:\\n- There are 23 instances in the original file where Gender, Age_at_diagnosis, or Race feature values are ‘--’, or ‘not reported’. These instances were filtered out in the preprocessed dataset.\\n- Despite being present in the original dataset, we do not include the columns Project, Case_ID, and Primary_Diagnosis columns in the preprocessed dataset.\\n- Age_at_diagnosis feature values were converted from string to continuous value by adding day information to the corresponding year information in the dataset as a floating-point number for the preprocessing stage.\\n\\nAll processed and unprocessed files also exist in this directory. \\n\\nBelow is a list of the additional columns of the original dataset file (and their corresponding description):\\n- Project column represents corresponding TCGA-LGG or TCGA-GBM project names.\\n- Case_ID column refers to the related project Case_ID information.\\n- Primary_Diagnosis column provides information related to the type of primary diagnosis. ', 'variable_info': None, 'citation': 'Tasci, E., Zhuge, Y., Kaur, H., Camphausen, K., & Krauze, A. V. (2022). Hierarchical Voting-Based Feature Selection and Ensemble Learning Model Scheme for Glioma Grading with Clinical and Molecular Characteristics. International Journal of Molecular Sciences, 23(22), 14155.'}}\n",
      "                name     role         type demographic  \\\n",
      "0              Grade   Target  Categorical        None   \n",
      "1             Gender  Feature  Categorical      Gender   \n",
      "2   Age_at_diagnosis  Feature   Continuous         Age   \n",
      "3               Race  Feature  Categorical        Race   \n",
      "4               IDH1  Feature  Categorical        None   \n",
      "5               TP53  Feature  Categorical        None   \n",
      "6               ATRX  Feature  Categorical        None   \n",
      "7               PTEN  Feature  Categorical        None   \n",
      "8               EGFR  Feature  Categorical        None   \n",
      "9                CIC  Feature  Categorical        None   \n",
      "10             MUC16  Feature  Categorical        None   \n",
      "11            PIK3CA  Feature  Categorical        None   \n",
      "12               NF1  Feature  Categorical        None   \n",
      "13            PIK3R1  Feature  Categorical        None   \n",
      "14             FUBP1  Feature  Categorical        None   \n",
      "15               RB1  Feature  Categorical        None   \n",
      "16            NOTCH1  Feature  Categorical        None   \n",
      "17              BCOR  Feature  Categorical        None   \n",
      "18             CSMD3  Feature  Categorical        None   \n",
      "19           SMARCA4  Feature  Categorical        None   \n",
      "20            GRIN2A  Feature  Categorical        None   \n",
      "21              IDH2  Feature  Categorical        None   \n",
      "22              FAT4  Feature  Categorical        None   \n",
      "23            PDGFRA  Feature  Categorical        None   \n",
      "\n",
      "                                          description  units missing_values  \n",
      "0   Glioma grade class information (0 = \"LGG\"; 1 =...    N/A             no  \n",
      "1                   Gender (0 = \"male\"; 1 = \"female\")    N/A             no  \n",
      "2   Age at diagnosis with the calculated number of...  years             no  \n",
      "3   Race  (0 = \"white\";  1 = \"black or african Ame...    N/A             no  \n",
      "4   isocitrate dehydrogenase (NADP(+))1 (0 = NOT_M...    N/A             no  \n",
      "5    tumor protein p53 (0 = NOT_MUTATED; 1 = MUTATED)    N/A             no  \n",
      "6   ATRX chromatin remodeler (0 = NOT_MUTATED; 1 =...    N/A             no  \n",
      "7   phosphatase and tensin homolog (0 = NOT_MUTATE...    N/A             no  \n",
      "8   epidermal growth factor receptor (0 = NOT_MUTA...    N/A             no  \n",
      "9   capicua transcriptional repressor (0 = NOT_MUT...    N/A             no  \n",
      "10  mucin 16, cell surface associated (0 = NOT_MUT...    N/A             no  \n",
      "11  phosphatidylinositol-4,5-bisphosphate 3-kinase...    N/A             no  \n",
      "12     neurofibromin 1 (0 = NOT_MUTATED; 1 = MUTATED)    N/A             no  \n",
      "13  phosphoinositide-3-kinase regulatory subunit 1...    N/A             no  \n",
      "14  far upstream element binding protein 1 (0 = NO...    N/A             no  \n",
      "15  RB transcriptional corepressor 1 (0 = NOT_MUTA...    N/A             no  \n",
      "16    notch receptor 1 (0 = NOT_MUTATED; 1 = MUTATED)    N/A             no  \n",
      "17    BCL6 corepressor (0 = NOT_MUTATED; 1 = MUTATED)    N/A             no  \n",
      "18  CUB and Sushi multiple domains 3 (0 = NOT_MUTA...    N/A             no  \n",
      "19  SWI/SNF related, matrix associated, actin depe...    N/A             no  \n",
      "20  glutamate ionotropic receptor NMDA type subuni...    N/A             no  \n",
      "21  isocitrate dehydrogenase (NADP(+)) 2 (0 = NOT_...    N/A             no  \n",
      "22  FAT atypical cadherin 4 (0 = NOT_MUTATED; 1 = ...    N/A             no  \n",
      "23  platelet-derived growth factor receptor alpha ...    N/A             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "glioma_grading_clinical_and_mutation_features = fetch_ucirepo(id=759) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = glioma_grading_clinical_and_mutation_features.data.features \n",
    "y = glioma_grading_clinical_and_mutation_features.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(glioma_grading_clinical_and_mutation_features.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(glioma_grading_clinical_and_mutation_features.variables) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. import Python liberaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([839])\n",
      "Training data batches:\n",
      "torch.Size([100, 23]) torch.Size([100])\n",
      "torch.Size([100, 23]) torch.Size([100])\n",
      "torch.Size([100, 23]) torch.Size([100])\n",
      "torch.Size([100, 23]) torch.Size([100])\n",
      "torch.Size([100, 23]) torch.Size([100])\n",
      "torch.Size([100, 23]) torch.Size([100])\n",
      "torch.Size([71, 23]) torch.Size([71])\n",
      "\n",
      "Test data batches:\n",
      "torch.Size([100, 23]) torch.Size([100])\n",
      "torch.Size([68, 23]) torch.Size([68])\n"
     ]
    }
   ],
   "source": [
    "# Convert them to numpy arrays and replace race info\n",
    "X_numpy = X.to_numpy()\n",
    "y_numpy = y.to_numpy()\n",
    "\n",
    "my_dict = {'white': 0, 'black or african american': 1, 'asian': 2, 'american indian or alaska native':3}\n",
    "for element in X_numpy:\n",
    "    if element[2]=='white':\n",
    "        element[2] = 0\n",
    "    elif element[2]=='black or african american':\n",
    "        element[2] = 1\n",
    "    elif element[2]== 'asian':\n",
    "        element[2] = 2\n",
    "    elif element[2]== 'american indian or alaska native':\n",
    "        element[2] = 3\n",
    "X_numpy = X_numpy.astype(float)\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_tensor = torch.tensor(X_numpy, dtype=torch.float)\n",
    "y_tensor = torch.tensor(y_numpy, dtype=torch.long)\n",
    "y_tensor = y_tensor.squeeze()\n",
    "print(y_tensor.shape)\n",
    "# Create a TensorDataset\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "# Hyper-parameters \n",
    "input_size = 23\n",
    "hidden_size = 10\n",
    "num_classes = 2\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "batch_size = 100\n",
    "# Define the sizes for training and test datasets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "print(\"Training data batches:\")\n",
    "for X, y in train_loader:\n",
    "    print(X.shape, y.shape)\n",
    "    \n",
    "print(\"\\nTest data batches:\")\n",
    "for X, y in test_loader:\n",
    "    print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Device configuration: check if there is a configured GPU available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# Define a model using class NeuralNet()\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# Define loss function and optimization algorithm (optimizer)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.1227\n",
      "Accuracy on test set: 60.12%\n",
      "Accuracy of the network on the training inputs: 57.52608047690015 %\n",
      "Epoch [2/10], Loss: 0.7509\n",
      "Accuracy on test set: 60.12%\n",
      "Accuracy of the network on the training inputs: 57.52608047690015 %\n",
      "Epoch [3/10], Loss: 0.6732\n",
      "Accuracy on test set: 57.74%\n",
      "Accuracy of the network on the training inputs: 57.67511177347243 %\n",
      "Epoch [4/10], Loss: 0.6794\n",
      "Accuracy on test set: 42.26%\n",
      "Accuracy of the network on the training inputs: 45.007451564828614 %\n",
      "Epoch [5/10], Loss: 0.6380\n",
      "Accuracy on test set: 42.86%\n",
      "Accuracy of the network on the training inputs: 45.30551415797317 %\n",
      "Epoch [6/10], Loss: 0.6773\n",
      "Accuracy on test set: 49.40%\n",
      "Accuracy of the network on the training inputs: 52.60804769001491 %\n",
      "Epoch [7/10], Loss: 0.6721\n",
      "Accuracy on test set: 70.83%\n",
      "Accuracy of the network on the training inputs: 68.4053651266766 %\n",
      "Epoch [8/10], Loss: 0.6716\n",
      "Accuracy on test set: 71.43%\n",
      "Accuracy of the network on the training inputs: 70.04470938897168 %\n",
      "Epoch [9/10], Loss: 0.6579\n",
      "Accuracy on test set: 71.43%\n",
      "Accuracy of the network on the training inputs: 74.3666169895678 %\n",
      "Epoch [10/10], Loss: 0.6581\n",
      "Accuracy on test set: 78.57%\n",
      "Accuracy of the network on the training inputs: 80.02980625931446 %\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "test_acc_list, train_acc_list = [], []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute the loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Optimize\n",
    "        \n",
    "\n",
    "    # Print average loss at the end of each epoch\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Evaluation on Test Set\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f\"Accuracy on test set: {(100 * correct / total):.2f}%\")\n",
    "    with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for inputs, labels in train_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "    \n",
    "            print('Accuracy of the network on the training inputs: {} %'.format(100 * correct / total))\n",
    "            train_acc_list.append(100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
